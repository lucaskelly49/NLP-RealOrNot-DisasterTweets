{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/nlp-getting-started/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to do with NLTK:\n",
    "\n",
    "* Stop word removal\n",
    "* Filtering and cleaning\n",
    "* Feature selection and engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "from  nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=df_train[df_train['target']==1]\n",
    "false=df_train[df_train['target']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words and punctuation from this one tweet\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(string.punctuation)\n",
    "stopwords_list += ['A', 'http', 'https', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9','@', '‘','said','says', \"'s\",'”','“', ':', '#', 'a', '...'] #Miscelleneous and numerical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-09f83278b8f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Decided to include a for loop to capatilize the stop words due to capitalization in headings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mstopwords_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in stopwords_list: #Decided to include a for loop to capatilize the stop words due to capitalization in headings. \n",
    "    if len(x) == 1:\n",
    "        stopwords_list.append(x.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_true = true['text'].apply(nltk.word_tokenize) #Tokenizing \n",
    "tokenized_false = false['text'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Our, Deeds, are, the, Reason, of, this, #, ea...\n",
       "1        [Forest, fire, near, La, Ronge, Sask, ., Canada]\n",
       "2       [All, residents, asked, to, 'shelter, in, plac...\n",
       "3       [13,000, people, receive, #, wildfires, evacua...\n",
       "4       [Just, got, sent, this, photo, from, Ruby, #, ...\n",
       "                              ...                        \n",
       "7608    [Two, giant, cranes, holding, a, bridge, colla...\n",
       "7609    [@, aria_ahrary, @, TheTawniest, The, out, of,...\n",
       "7610    [M1.94, [, 01:04, UTC, ], ?, 5km, S, of, Volca...\n",
       "7611    [Police, investigating, after, an, e-bike, col...\n",
       "7612    [The, Latest, :, More, Homes, Razed, by, North...\n",
       "Name: text, Length: 3271, dtype: object"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tokens=[] #Use this to take out all of the stop words \n",
    "for x in tokenized_true:\n",
    "    for y in x:\n",
    "        if y not in stopwords_list:\n",
    "            true_tokens.append(y.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "FreqDist_true = dict(FreqDist(true_tokens).most_common(10)) #Freq Dist of the token values for positive values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 329,\n",
       " 'the': 285,\n",
       " 'fire': 177,\n",
       " 'news': 140,\n",
       " 'amp': 135,\n",
       " 'via': 121,\n",
       " \"n't\": 120,\n",
       " 'disaster': 118,\n",
       " 'in': 113,\n",
       " 'california': 111}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### working on frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the tokens sentence as an example\n",
    "\n",
    "freqdist = FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Forest', 1),\n",
       " ('fire', 1),\n",
       " ('near', 1),\n",
       " ('La', 1),\n",
       " ('Ronge', 1),\n",
       " ('Sask', 1),\n",
       " ('.', 1),\n",
       " ('Canada', 1)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common = freqdist.most_common(200)\n",
    "most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize whole DF\n",
    "\n",
    "df_train['tokenized_text'] = df_train['text_stopwords_rem'].apply(word_tokenize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=df_train[df_train['target']==1]\n",
    "false=df_train[df_train['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #NLTK NLP Package\n",
    "from nltk.tokenize import word_tokenize #NLTK NLP Package\n",
    "tokenized_true=true['tokenized_text']\n",
    "tokenized_false=false['tokenized_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Our, Deeds, Reason, #, earthquake, May, ALLAH...\n",
       "1        [Forest, fire, near, La, Ronge, Sask, ., Canada]\n",
       "2       [All, residents, asked, 'shelter, place, ', no...\n",
       "3       [13,000, people, receive, #, wildfires, evacua...\n",
       "4       [Just, got, sent, photo, Ruby, #, Alaska, smok...\n",
       "                              ...                        \n",
       "7608    [Two, giant, cranes, holding, bridge, collapse...\n",
       "7609    [@, aria_ahrary, @, TheTawniest, The, control,...\n",
       "7610    [M1.94, [, 01:04, UTC, ], ?, 5km, S, Volcano, ...\n",
       "7611    [Police, investigating, e-bike, collided, car,...\n",
       "7612    [The, Latest, :, More, Homes, Razed, Northern,...\n",
       "Name: tokenized_text, Length: 3271, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tokens=[] #Use this to take out all of the stop words \n",
    "for x in tokenized_true:\n",
    "    for y in x:\n",
    "        true_tokens.append(y.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "FreqDist_true = dict(FreqDist(true_tokens).most_common(20)) #Freq Dist of the token values for positive values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':': 3645,\n",
       " 'http': 2380,\n",
       " '#': 1701,\n",
       " '.': 1098,\n",
       " '@': 896,\n",
       " '?': 751,\n",
       " '...': 637,\n",
       " 'i': 335,\n",
       " '!': 324,\n",
       " \"'\": 303,\n",
       " 'the': 294,\n",
       " ';': 248,\n",
       " \"'s\": 241,\n",
       " 'a': 195,\n",
       " 'fire': 177,\n",
       " '&': 164,\n",
       " ')': 143,\n",
       " '(': 142,\n",
       " 'news': 140,\n",
       " 'amp': 135}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
